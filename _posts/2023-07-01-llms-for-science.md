---
layout: post
title:  "LLMs for Science"
date:   2023-07-01 18:18:24 +0200
tags: update
comments: true
---

Where does the LLM journey go?

Prompting improvements

Integration with existing knowledge bases

Integration with APIs

Central to understanding of LLMs are emergant behaviors. Where the old approaches
where to build pipelines that account for each step of the reasoning process
(e.g. classify objects in an image, then perform action on top of each of the
objects), more complex (i.e. foundational) models are able to take more control
of the processing chain.

LLMs in that sense link into modern work, where re-skilling is a neccessity based
on the speed at which technology is evolving.
(TODO: Kurzweil innovation cycles, expontential growth, etc.)
They make it easier to swift through emerging knowledge in various fields and find
connections between different areas to augment the speed of our learning.
(And even pull in learning directly into the work by providing stronger feedback loops.
One could argue that is one of the things github copilot does.)

TODO: Go into details about LLMs

TODO: explore different options

## Experimentations

TODO: some code in langchain to play around with that?

## Citations

[1] J. Wei et al., “Chain-of-thought prompting elicits reasoning in large language models,” arXiv [cs.CL], Jan. 27, 2022. Accessed: Jun. 30, 2023. [Online]. Available: <https://openreview.net/pdf?id=_VjQlMeSB_J>

[2] Tree-of-Thought

[3] S. Pan, L. Luo, Y. Wang, C. Chen, J. Wang, and X. Wu, “Unifying large language models and Knowledge Graphs: A roadmap,” arXiv [cs.CL], Jun. 14, 2023. Accessed: Jun. 26, 2023. [Online]. Available: <http://arxiv.org/abs/2306.08302>

[4] TOOLFORMERS

[5] Complexity Book
